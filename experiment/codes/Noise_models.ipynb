{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b88751-c300-471c-94c2-ae4c3dc7035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Noise Models for 4DSTEM, including Low-Dose Direct Detector\n",
    "\n",
    "This module provides noise models that simulate typical noise types in electorn microscopy,\n",
    "including modern direct electron detectors. They can be applied directly to a py4DSTEM datacube:\n",
    "\n",
    "- Poisson (shot noise)\n",
    "- Readout Gaussian\n",
    "- Dark current\n",
    "- Salt and Pepper\n",
    "- Correlated\n",
    "- Drizzle near bright\n",
    "- Very sparse signal (few electron counts per pattern)\n",
    "- Homogeneous zero background\n",
    "- Single electron counting statistics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Dict, Any, Tuple\n",
    "import py4DSTEM\n",
    "\n",
    "# ============================================================================\n",
    "# Abstract base class for noise models\n",
    "# ============================================================================\n",
    "class NoiseModel(ABC):\n",
    "    \"\"\"Base class for noise models\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def apply(self, data: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply noise to the data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data array\n",
    "        **kwargs : additional parameters for the noise model\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with noise added\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# ============================================================================\n",
    "# Concrete noise model implementations. More models can be added if necessary.\n",
    "# ============================================================================\n",
    "class PoissonNoise(NoiseModel):\n",
    "    \"\"\"Shot noise following Poisson statistics\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, scale: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Poisson noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (should be non-negative)\n",
    "        scale : float\n",
    "            Scaling factor for intensity before applying Poisson\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with Poisson noise\n",
    "        \"\"\"\n",
    "        # Scale data, apply Poisson, scale back\n",
    "        scaled = data * scale\n",
    "        noisy = np.random.poisson(scaled)\n",
    "        return noisy / scale\n",
    "\n",
    "\n",
    "class GaussianNoise(NoiseModel):\n",
    "    \"\"\"Additive Gaussian (normal) noise\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, mean: float = 0.0, \n",
    "              sigma: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Gaussian noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        mean : float\n",
    "            Mean of Gaussian distribution\n",
    "        sigma : float\n",
    "            Standard deviation of Gaussian distribution\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with Gaussian noise added\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(mean, sigma, data.shape)\n",
    "        return data + noise\n",
    "\n",
    "\n",
    "class ReadoutNoise(NoiseModel):\n",
    "    \"\"\"Detector readout noise (Gaussian)\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, sigma: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply readout noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        sigma : float\n",
    "            Standard deviation of readout noise in counts\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with readout noise added\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(0, sigma, data.shape)\n",
    "        return data + noise\n",
    "\n",
    "\n",
    "class DarkCurrentNoise(NoiseModel):\n",
    "    \"\"\"Dark current noise (Poisson-distributed)\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, dark_current: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply dark current noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        dark_current : float\n",
    "            Mean dark current in counts per pixel\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with dark current noise added\n",
    "        \"\"\"\n",
    "        dark = np.random.poisson(dark_current, data.shape)\n",
    "        return data + dark\n",
    "\n",
    "\n",
    "class SaltPepperNoise(NoiseModel):\n",
    "    \"\"\"Salt and pepper (impulse) noise\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, probability: float = 0.01,\n",
    "              salt_value: Optional[float] = None,\n",
    "              pepper_value: float = 0.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply salt and pepper noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        probability : float\n",
    "            Probability of a pixel being affected (total for both salt and pepper)\n",
    "        salt_value : float, optional\n",
    "            Value for 'salt' pixels. If None, uses max of data\n",
    "        pepper_value : float\n",
    "            Value for 'pepper' pixels\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with salt and pepper noise\n",
    "        \"\"\"\n",
    "        noisy = data.copy()\n",
    "        \n",
    "        if salt_value is None:\n",
    "            salt_value = np.max(data)\n",
    "        \n",
    "        # Salt noise\n",
    "        salt_mask = np.random.random(data.shape) < (probability / 2)\n",
    "        noisy[salt_mask] = salt_value\n",
    "        \n",
    "        # Pepper noise\n",
    "        pepper_mask = np.random.random(data.shape) < (probability / 2)\n",
    "        noisy[pepper_mask] = pepper_value\n",
    "        \n",
    "        return noisy\n",
    "\n",
    "\n",
    "class CorrelatedNoise(NoiseModel):\n",
    "    \"\"\"Spatially correlated noise (low-frequency)\"\"\"\n",
    "    \n",
    "    def apply(self, data: np.ndarray, sigma: float = 1.0,\n",
    "              correlation_length: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply correlated noise using Gaussian filtering\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        sigma : float\n",
    "            Amplitude of noise\n",
    "        correlation_length : float\n",
    "            Correlation length in pixels\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Data with correlated noise added\n",
    "        \"\"\"\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        \n",
    "        # Generate white noise\n",
    "        white_noise = np.random.normal(0, sigma, data.shape)\n",
    "        \n",
    "        # Smooth to create correlations\n",
    "        correlated = gaussian_filter(white_noise, sigma=correlation_length)\n",
    "        \n",
    "        return data + correlated\n",
    "\n",
    "class DrizzleNearBrightPoissonNoise(NoiseModel):\n",
    "    \"\"\"\n",
    "    For the brightest p% pixels, drizzle Poisson-distributed counts onto\n",
    "    K randomly chosen pixels within a radius (<=radius_px) AND within a square window (square_side x square_side).\n",
    "\n",
    "    This creates \"correlated\" salt-like noise near bright features.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        bright_fraction: float = 0.01,     # 1% brightest pixels\n",
    "        radius_px: int = 5,                # within distance <= 5 pixels\n",
    "        square_side: int = 10,             # within 10x10 window\n",
    "        drizzles_per_seed: int = 3,        # drizzle onto 3 pixels per bright seed\n",
    "        lam_fraction: float = 0.05,        # lambda = lam_fraction * seed_intensity\n",
    "        lam_min: float = 1.0,              # minimum lambda\n",
    "        exclude_center: bool = True,       # don't drizzle onto the seed pixel itself\n",
    "        rng: Optional[np.random.Generator] = None,\n",
    "    ) -> np.ndarray:\n",
    "        if rng is None:\n",
    "            rng = np.random.default_rng()\n",
    "\n",
    "        img = np.asarray(data, dtype=np.float32, order=\"C\")\n",
    "        h, w = img.shape\n",
    "\n",
    "        # --- choose brightest pixels (top bright_fraction) ---\n",
    "        if not (0.0 < bright_fraction < 1.0):\n",
    "            raise ValueError(\"bright_fraction must be in (0,1)\")\n",
    "\n",
    "        thr = np.quantile(img, 1.0 - bright_fraction)\n",
    "        seeds = np.argwhere(img >= thr)  # array of (y, x)\n",
    "\n",
    "        if seeds.size == 0:\n",
    "            return img.copy()\n",
    "\n",
    "        # --- candidate offsets in a square window, additionally constrained by radius ---\n",
    "        half = square_side // 2\n",
    "        # For square_side=10 -> offsets [-5,4] (10 values), matching your 10x10 wording\n",
    "        ys = np.arange(-half, -half + square_side, dtype=int)\n",
    "        xs = np.arange(-half, -half + square_side, dtype=int)\n",
    "        dy, dx = np.meshgrid(ys, xs, indexing=\"ij\")\n",
    "        dy = dy.ravel()\n",
    "        dx = dx.ravel()\n",
    "\n",
    "        # radius constraint\n",
    "        mask_r = (dy * dy + dx * dx) <= (radius_px * radius_px)\n",
    "        if exclude_center:\n",
    "            mask_r &= ~((dy == 0) & (dx == 0))\n",
    "\n",
    "        dy = dy[mask_r]\n",
    "        dx = dx[mask_r]\n",
    "        n_candidates = dy.size\n",
    "        if n_candidates == 0:\n",
    "            return img.copy()\n",
    "\n",
    "        out = img.copy()\n",
    "\n",
    "        # --- drizzle loop ---\n",
    "        for (y, x) in seeds:\n",
    "            seed_intensity = float(img[y, x])\n",
    "            lam = max(lam_min, lam_fraction * seed_intensity)\n",
    "\n",
    "            # pick K distinct offsets\n",
    "            k = min(drizzles_per_seed, n_candidates)\n",
    "            pick = rng.choice(n_candidates, size=k, replace=False)\n",
    "\n",
    "            yy = y + dy[pick]\n",
    "            xx = x + dx[pick]\n",
    "\n",
    "            # in-bounds\n",
    "            inb = (yy >= 0) & (yy < h) & (xx >= 0) & (xx < w)\n",
    "            yy = yy[inb]\n",
    "            xx = xx[inb]\n",
    "            if yy.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Poisson drizzle counts\n",
    "            drizzle = rng.poisson(lam, size=yy.size).astype(np.float32)\n",
    "            out[yy, xx] += drizzle\n",
    "\n",
    "        return out\n",
    "\n",
    "# ============================================================================\n",
    "# Main function to add noise to datacube\n",
    "# ============================================================================\n",
    "\n",
    "def add_noise_to_datacube(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    noise_models: list[tuple[NoiseModel, Dict[str, Any]]],\n",
    "    seed: Optional[int] = None,\n",
    "    clip_negative: bool = True,\n",
    "    preserve_dtype: bool = True  # NEW parameter\n",
    ") -> py4DSTEM.DataCube:\n",
    "    \"\"\"\n",
    "    Add noise to Q-space (diffraction patterns) in a 4DSTEM datacube\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube\n",
    "    noise_models : list of tuples\n",
    "        List of (NoiseModel instance, parameters dict) to apply sequentially\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    clip_negative : bool\n",
    "        Whether to clip negative values to zero after adding noise\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    py4DSTEM.DataCube\n",
    "        New datacube with noise added\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Single noise source\n",
    "    >>> noisy = add_noise_to_datacube(\n",
    "    ...     datacube,\n",
    "    ...     [(PoissonNoise(), {'scale': 100})]\n",
    "    ... )\n",
    "    \n",
    "    >>> # Multiple noise sources\n",
    "    >>> noisy = add_noise_to_datacube(\n",
    "    ...     datacube,\n",
    "    ...     [\n",
    "    ...         (PoissonNoise(), {'scale': 100}),\n",
    "    ...         (ReadoutNoise(), {'sigma': 5}),\n",
    "    ...         (DarkCurrentNoise(), {'dark_current': 2})\n",
    "    ...     ],\n",
    "    ...     seed=42\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Store original dtype\n",
    "    original_dtype = datacube.data.dtype\n",
    "    \n",
    "    # Copy the data\n",
    "    noisy_data = datacube.data.copy().astype(float)\n",
    "    \n",
    "    # Get shape\n",
    "    scan_i, scan_j, det_i, det_j = noisy_data.shape\n",
    "    \n",
    "    print(f\"Adding noise to datacube of shape {noisy_data.shape}\")\n",
    "    \n",
    "    # Apply each noise model sequentially to each diffraction pattern\n",
    "    for noise_idx, (noise_model, params) in enumerate(noise_models):\n",
    "        print(f\"Applying {noise_model.__class__.__name__} with params {params}...\")\n",
    "        \n",
    "        # Apply noise to each diffraction pattern in Q-space\n",
    "        for i in range(scan_i):\n",
    "            for j in range(scan_j):\n",
    "                # Get diffraction pattern\n",
    "                dp = noisy_data[i, j, :, :]\n",
    "                \n",
    "                # Apply noise\n",
    "                noisy_dp = noise_model.apply(dp, **params)\n",
    "                \n",
    "                # Store back\n",
    "                noisy_data[i, j, :, :] = noisy_dp\n",
    "    \n",
    "    # Clip negative values if requested\n",
    "    if clip_negative:\n",
    "        noisy_data = np.maximum(noisy_data, 0)\n",
    "    \n",
    "    # Convert back to original dtype to save space\n",
    "    if preserve_dtype:\n",
    "        # Get the max value for the dtype to avoid overflow\n",
    "        if np.issubdtype(original_dtype, np.integer):\n",
    "            dtype_max = np.iinfo(original_dtype).max\n",
    "            noisy_data = np.clip(noisy_data, 0, dtype_max)\n",
    "        noisy_data = noisy_data.astype(original_dtype)\n",
    "    \n",
    "    # Create new datacube\n",
    "    noisy_datacube = py4DSTEM.DataCube(data=noisy_data)\n",
    "    \n",
    "    # Copy calibration if it exists\n",
    "    if hasattr(datacube, 'calibration'):\n",
    "        noisy_datacube.calibration = datacube.calibration\n",
    "    \n",
    "    # Store noise information in metadata\n",
    "    noisy_datacube.metadata['noise_applied'] = [\n",
    "        {\n",
    "            'model': model.__class__.__name__,\n",
    "            'parameters': params\n",
    "        }\n",
    "        for model, params in noise_models\n",
    "    ]\n",
    "    \n",
    "    print(\"Noise addition complete!\")\n",
    "    return noisy_datacube\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Convenience function for common noise combinations\n",
    "# ============================================================================\n",
    "\n",
    "def add_realistic_detector_noise(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    dose_scale: float = 100,\n",
    "    readout_sigma: float = 5.0,\n",
    "    dark_current: float = 1.0,\n",
    "    seed: Optional[int] = None\n",
    ") -> py4DSTEM.DataCube:\n",
    "    \"\"\"\n",
    "    Add realistic detector noise (Poisson + readout + dark current)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube\n",
    "    dose_scale : float\n",
    "        Scaling for shot noise (higher = more signal, less relative noise)\n",
    "    readout_sigma : float\n",
    "        Readout noise standard deviation in counts\n",
    "    dark_current : float\n",
    "        Mean dark current in counts per pixel\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    py4DSTEM.DataCube\n",
    "        Datacube with realistic noise\n",
    "    \"\"\"\n",
    "    noise_models = [\n",
    "        (PoissonNoise(), {'scale': dose_scale}),\n",
    "        (DarkCurrentNoise(), {'dark_current': dark_current}),\n",
    "        (ReadoutNoise(), {'sigma': readout_sigma})\n",
    "    ]\n",
    "    \n",
    "    return add_noise_to_datacube(datacube, noise_models, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Low-Dose Specific Noise Models\n",
    "# ============================================================================\n",
    "\n",
    "class LowDoseDirectDetector(ABC):\n",
    "    \"\"\"Base class for low-dose direct detector simulation\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def apply(self, data: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SparsePoissonNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Sparse Poisson noise for low-dose conditions\n",
    "    \n",
    "    Simulates electron counting with very low dose, resulting in:\n",
    "    - Mostly zero pixels\n",
    "    - Few bright pixels (electron hits)\n",
    "    - Poisson statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        dose_fraction: float = 0.01,\n",
    "        ensure_sparse: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply sparse Poisson noise for low-dose imaging\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (will be used as intensity map)\n",
    "        dose_fraction : float\n",
    "            Fraction of total dose to use (0.01 = 1% of electrons)\n",
    "            Lower = sparser signal\n",
    "        ensure_sparse : bool\n",
    "            If True, enforces that most pixels are zero\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Sparse, low-dose data with Poisson noise\n",
    "        \"\"\"\n",
    "        # Normalize input to get probability distribution\n",
    "        data_norm = data.astype(float)\n",
    "        data_norm = data_norm / (np.sum(data_norm) + 1e-10)\n",
    "        \n",
    "        # Calculate expected number of electrons for this pattern\n",
    "        total_electrons = np.sum(data) * dose_fraction\n",
    "        \n",
    "        # Sample from Poisson distribution\n",
    "        # Expected counts = normalized intensity Ã— total electrons\n",
    "        expected_counts = data_norm * total_electrons\n",
    "        \n",
    "        # Apply Poisson noise\n",
    "        noisy = np.random.poisson(expected_counts)\n",
    "        \n",
    "        if ensure_sparse:\n",
    "            # Make sure we have mostly zeros\n",
    "            sparsity = np.sum(noisy == 0) / noisy.size\n",
    "            if sparsity < 0.9:  # Less than 90% zeros\n",
    "                # Reduce dose further to ensure sparsity\n",
    "                scale_factor = 0.5\n",
    "                noisy = np.random.poisson(expected_counts * scale_factor)\n",
    "        \n",
    "        return noisy.astype(data.dtype)\n",
    "\n",
    "\n",
    "class ElectronCountingNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Electron counting detector noise with discrete electrons\n",
    "    \n",
    "    Simulates:\n",
    "    - Individual electron events\n",
    "    - Sparse distribution\n",
    "    - Optional detector quantum efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        electrons_per_pattern: float = 100,\n",
    "        dqe: float = 1.0,\n",
    "        spread_sigma: float = 0.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply electron counting noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (used as probability map for electron positions)\n",
    "        electrons_per_pattern : float\n",
    "            Average number of electrons to detect per pattern\n",
    "        dqe : float\n",
    "            Detective quantum efficiency (fraction of electrons detected)\n",
    "            1.0 = perfect detector, 0.7 = typical\n",
    "        spread_sigma : float\n",
    "            Gaussian spread of electron signal (pixels)\n",
    "            0 = point detector, >0 = some blur\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Electron counting data\n",
    "        \"\"\"\n",
    "        # Normalize to probability distribution\n",
    "        prob_map = data.astype(float)\n",
    "        prob_map = prob_map / (np.sum(prob_map) + 1e-10)\n",
    "        \n",
    "        # Sample number of electrons (Poisson distributed)\n",
    "        n_electrons = np.random.poisson(electrons_per_pattern)\n",
    "        \n",
    "        # Apply DQE (some electrons not detected)\n",
    "        n_detected = np.random.binomial(n_electrons, dqe)\n",
    "        \n",
    "        # Initialize output\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_detected > 0:\n",
    "            # Flatten probability map for sampling\n",
    "            prob_flat = prob_map.flatten()\n",
    "            \n",
    "            # Sample electron positions\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_detected,\n",
    "                p=prob_flat,\n",
    "                replace=True\n",
    "            )\n",
    "            \n",
    "            # Convert to 2D indices\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            \n",
    "            if spread_sigma > 0:\n",
    "                # Add some spread to electron positions (point spread function)\n",
    "                for y, x in zip(*positions):\n",
    "                    # Add Gaussian spread\n",
    "                    y_spread = y + np.random.normal(0, spread_sigma)\n",
    "                    x_spread = x + np.random.normal(0, spread_sigma)\n",
    "                    \n",
    "                    # Clip to valid range\n",
    "                    y_int = int(np.clip(y_spread, 0, data.shape[0] - 1))\n",
    "                    x_int = int(np.clip(x_spread, 0, data.shape[1] - 1))\n",
    "                    \n",
    "                    output[y_int, x_int] += 1\n",
    "            else:\n",
    "                # Point detector - just count electrons at each position\n",
    "                for y, x in zip(*positions):\n",
    "                    output[y, x] += 1\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "class BimodalSparseNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Bimodal sparse noise: large spike at zero + Gaussian distribution for signal\n",
    "    \n",
    "    Creates histogram with:\n",
    "    - Large bin at 0 (background, 95-99% of pixels)\n",
    "    - Gaussian distribution centered at signal_mean for non-zero pixels\n",
    "    - Clear separation between background and signal\n",
    "    \n",
    "    This is ideal for training denoisers on sparse data with distinct\n",
    "    background and signal populations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        sparsity_target: float = 0.98,\n",
    "        signal_mean: float = 30.0,\n",
    "        signal_sigma: float = 10.0,\n",
    "        min_signal: float = 5.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply bimodal sparse noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (used as probability map for signal positions)\n",
    "        sparsity_target : float\n",
    "            Target fraction of zero pixels (0.98 = 98% zeros)\n",
    "        signal_mean : float\n",
    "            Mean value for non-zero signal pixels\n",
    "        signal_sigma : float\n",
    "            Standard deviation for signal distribution\n",
    "        min_signal : float\n",
    "            Minimum value for signal pixels (clips low values)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Bimodal sparse data with clear zero peak and signal distribution\n",
    "        \"\"\"\n",
    "        # Normalize to probability distribution\n",
    "        prob_map = data.astype(float)\n",
    "        total_intensity = np.sum(prob_map)\n",
    "        \n",
    "        if total_intensity > 0:\n",
    "            prob_map = prob_map / total_intensity\n",
    "        else:\n",
    "            prob_map = np.ones_like(prob_map) / prob_map.size\n",
    "        \n",
    "        # Calculate number of signal pixels\n",
    "        total_pixels = data.size\n",
    "        n_signal_pixels = int(total_pixels * (1 - sparsity_target))\n",
    "        \n",
    "        # Initialize output with zeros\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_signal_pixels > 0:\n",
    "            # Sample positions for signal pixels\n",
    "            prob_flat = prob_map.flatten()\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_signal_pixels,\n",
    "                p=prob_flat,\n",
    "                replace=True  # Allow repeating pixels\n",
    "            )\n",
    "            \n",
    "            # Generate signal values from Gaussian distribution\n",
    "            signal_values = np.random.normal(signal_mean, signal_sigma, n_signal_pixels)\n",
    "            \n",
    "            # Clip to minimum signal value\n",
    "            signal_values = np.maximum(signal_values, min_signal)\n",
    "            \n",
    "            # Assign to positions\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            output[positions] = signal_values\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "class LowDoseSparseModel(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Combined low-dose model with extreme sparsity\n",
    "    \n",
    "    Creates data that is:\n",
    "    - >95% zeros\n",
    "    - Sparse electron counts\n",
    "    - Normally distributed signal in non-zero pixels\n",
    "    - Homogeneous zero background\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        sparsity_target: float = 0.98,\n",
    "        mean_electrons: float = 50,\n",
    "        add_readout: bool = False,\n",
    "        readout_sigma: float = 1.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply extreme low-dose sparse noise model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        sparsity_target : float\n",
    "            Target fraction of zero pixels (0.98 = 98% zeros)\n",
    "        mean_electrons : float\n",
    "            Mean number of electrons per pattern\n",
    "        add_readout : bool\n",
    "            Whether to add readout noise (usually False for counting detectors)\n",
    "        readout_sigma : float\n",
    "            Readout noise standard deviation (if added)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Extremely sparse low-dose data\n",
    "        \"\"\"\n",
    "        # Normalize to probability\n",
    "        prob_map = data.astype(float)\n",
    "        total_intensity = np.sum(prob_map)\n",
    "        \n",
    "        if total_intensity > 0:\n",
    "            prob_map = prob_map / total_intensity\n",
    "        else:\n",
    "            # If input is all zeros, use uniform probability\n",
    "            prob_map = np.ones_like(prob_map) / prob_map.size\n",
    "        \n",
    "        # Sample number of electrons\n",
    "        n_electrons = np.random.poisson(mean_electrons)\n",
    "        \n",
    "        # Calculate how many pixels to activate to achieve sparsity\n",
    "        total_pixels = data.size\n",
    "        target_active_pixels = int(total_pixels * (1 - sparsity_target))\n",
    "        \n",
    "        # Make sure we don't activate more pixels than we have electrons\n",
    "        n_activate = min(n_electrons, target_active_pixels)\n",
    "        \n",
    "        # Sample positions\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_activate > 0:\n",
    "            prob_flat = prob_map.flatten()\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_activate,\n",
    "                p=prob_flat,\n",
    "                replace=True\n",
    "            )\n",
    "            \n",
    "            # Add counts\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            for y, x in zip(*positions):\n",
    "                output[y, x] += 1\n",
    "        \n",
    "        # Optionally add minimal readout noise\n",
    "        if add_readout:\n",
    "            readout = np.random.normal(0, readout_sigma, data.shape)\n",
    "            output = output + readout\n",
    "            output = np.maximum(output, 0)  # Clip negatives\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Dose Scaling Functions\n",
    "# ============================================================================\n",
    "\n",
    "def reduce_dose(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    dose_fraction: float = 0.01,\n",
    "    method: str = 'sparse_poisson',\n",
    "    signal_mean: float = 30.0,\n",
    "    signal_sigma: float = 10.0\n",
    ") -> py4DSTEM.DataCube:\n",
    "    \"\"\"\n",
    "    Reduce dose of datacube to simulate low-dose conditions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube with normal dose\n",
    "    dose_fraction : float\n",
    "        Fraction of original dose (0.01 = 1%)\n",
    "    method : str\n",
    "        Method to use:\n",
    "        - 'sparse_poisson': Sparse Poisson sampling\n",
    "        - 'electron_counting': Discrete electron counting\n",
    "        - 'extreme_sparse': Extreme sparsity (>95% zeros)\n",
    "        - 'bimodal': Spike at zero + Gaussian signal distribution (RECOMMENDED)\n",
    "    signal_mean : float\n",
    "        Mean value for signal pixels (only for 'bimodal' method)\n",
    "    signal_sigma : float\n",
    "        Std dev for signal pixels (only for 'bimodal' method)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    py4DSTEM.DataCube\n",
    "        Low-dose datacube\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Bimodal distribution (spike at 0 + Gaussian signal)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.02, \n",
    "    ...                         method='bimodal', signal_mean=30)\n",
    "    \n",
    "    >>> # 1% dose with sparse Poisson\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.01)\n",
    "    \n",
    "    >>> # Discrete electron counting (~100 electrons/pattern)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.01, \n",
    "    ...                         method='electron_counting')\n",
    "    \n",
    "    >>> # Extremely sparse (98% zeros)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.005,\n",
    "    ...                         method='extreme_sparse')\n",
    "    \"\"\"\n",
    "    data = datacube.data\n",
    "    scan_i, scan_j, det_i, det_j = data.shape\n",
    "    \n",
    "    print(f\"Reducing dose to {dose_fraction*100:.2f}% using {method}\")\n",
    "    \n",
    "    # Select model\n",
    "    if method == 'bimodal':\n",
    "        # Bimodal: spike at zero + Gaussian signal\n",
    "        sparsity = 1 - dose_fraction  # dose_fraction = fraction of non-zero pixels\n",
    "        model = BimodalSparseNoise()\n",
    "        params = {\n",
    "            'sparsity_target': sparsity,\n",
    "            'signal_mean': signal_mean,\n",
    "            'signal_sigma': signal_sigma,\n",
    "            'min_signal': 5.0\n",
    "        }\n",
    "    \n",
    "    elif method == 'sparse_poisson':\n",
    "        model = SparsePoissonNoise()\n",
    "        params = {'dose_fraction': dose_fraction, 'ensure_sparse': True}\n",
    "    \n",
    "    elif method == 'electron_counting':\n",
    "        # Calculate electrons per pattern from dose fraction\n",
    "        avg_intensity = np.mean(data)\n",
    "        electrons = avg_intensity * dose_fraction * det_i * det_j\n",
    "        model = ElectronCountingNoise()\n",
    "        params = {'electrons_per_pattern': electrons, 'dqe': 0.95}\n",
    "    \n",
    "    elif method == 'extreme_sparse':\n",
    "        avg_intensity = np.mean(data)\n",
    "        electrons = avg_intensity * dose_fraction * det_i * det_j * 0.1\n",
    "        model = LowDoseSparseModel()\n",
    "        params = {\n",
    "            'sparsity_target': 0.98,\n",
    "            'mean_electrons': electrons,\n",
    "            'add_readout': False\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Apply to all patterns\n",
    "    low_dose_data = np.zeros_like(data)\n",
    "    \n",
    "    total = scan_i * scan_j\n",
    "    for idx, (i, j) in enumerate(np.ndindex(scan_i, scan_j)):\n",
    "        dp = data[i, j, :, :]\n",
    "        low_dose_dp = model.apply(dp, **params)\n",
    "        low_dose_data[i, j, :, :] = low_dose_dp\n",
    "        \n",
    "        if (idx + 1) % max(1, total // 10) == 0:\n",
    "            print(f\"  Progress: {idx+1}/{total}\")\n",
    "    \n",
    "    # Create new datacube\n",
    "    low_dose_cube = py4DSTEM.DataCube(data=low_dose_data)\n",
    "    \n",
    "    if hasattr(datacube, 'calibration'):\n",
    "        low_dose_cube.calibration = datacube.calibration\n",
    "    \n",
    "    # Store metadata\n",
    "    low_dose_cube.metadata['dose_reduction'] = {\n",
    "        'method': method,\n",
    "        'dose_fraction': dose_fraction,\n",
    "        'original_mean': float(np.mean(data)),\n",
    "        'reduced_mean': float(np.mean(low_dose_data)),\n",
    "        'sparsity': float(np.sum(low_dose_data == 0) / low_dose_data.size)\n",
    "    }\n",
    "    \n",
    "    print(f\"Done! Sparsity: {low_dose_cube.metadata['dose_reduction']['sparsity']*100:.1f}% zeros\")\n",
    "    \n",
    "    return low_dose_cube"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

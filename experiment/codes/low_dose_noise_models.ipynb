{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b88751-c300-471c-94c2-ae4c3dc7035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Low-Dose Direct Detector Noise Models for 4DSTEM\n",
    "\n",
    "This module provides noise models that simulate low-dose direct detector conditions:\n",
    "- Very sparse signal (few electron counts per pattern)\n",
    "- Poisson-dominated noise (shot noise)\n",
    "- Homogeneous zero background\n",
    "- Single electron counting statistics\n",
    "\n",
    "These models are optimized for training deep learning denoisers on sparse data.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Dict, Any, Tuple\n",
    "import py4DSTEM\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Low-Dose Specific Noise Models\n",
    "# ============================================================================\n",
    "\n",
    "class LowDoseDirectDetector(ABC):\n",
    "    \"\"\"Base class for low-dose direct detector simulation\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def apply(self, data: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SparsePoissonNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Sparse Poisson noise for low-dose conditions\n",
    "    \n",
    "    Simulates electron counting with very low dose, resulting in:\n",
    "    - Mostly zero pixels\n",
    "    - Few bright pixels (electron hits)\n",
    "    - Poisson statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        dose_fraction: float = 0.01,\n",
    "        ensure_sparse: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply sparse Poisson noise for low-dose imaging\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (will be used as intensity map)\n",
    "        dose_fraction : float\n",
    "            Fraction of total dose to use (0.01 = 1% of electrons)\n",
    "            Lower = sparser signal\n",
    "        ensure_sparse : bool\n",
    "            If True, enforces that most pixels are zero\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Sparse, low-dose data with Poisson noise\n",
    "        \"\"\"\n",
    "        # Normalize input to get probability distribution\n",
    "        data_norm = data.astype(float)\n",
    "        data_norm = data_norm / (np.sum(data_norm) + 1e-10)\n",
    "        \n",
    "        # Calculate expected number of electrons for this pattern\n",
    "        total_electrons = np.sum(data) * dose_fraction\n",
    "        \n",
    "        # Sample from Poisson distribution\n",
    "        # Expected counts = normalized intensity Ã— total electrons\n",
    "        expected_counts = data_norm * total_electrons\n",
    "        \n",
    "        # Apply Poisson noise\n",
    "        noisy = np.random.poisson(expected_counts)\n",
    "        \n",
    "        if ensure_sparse:\n",
    "            # Make sure we have mostly zeros\n",
    "            sparsity = np.sum(noisy == 0) / noisy.size\n",
    "            if sparsity < 0.9:  # Less than 90% zeros\n",
    "                # Reduce dose further to ensure sparsity\n",
    "                scale_factor = 0.5\n",
    "                noisy = np.random.poisson(expected_counts * scale_factor)\n",
    "        \n",
    "        return noisy.astype(data.dtype)\n",
    "\n",
    "\n",
    "class ElectronCountingNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Electron counting detector noise with discrete electrons\n",
    "    \n",
    "    Simulates:\n",
    "    - Individual electron events\n",
    "    - Sparse distribution\n",
    "    - Optional detector quantum efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        electrons_per_pattern: float = 100,\n",
    "        dqe: float = 1.0,\n",
    "        spread_sigma: float = 0.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply electron counting noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (used as probability map for electron positions)\n",
    "        electrons_per_pattern : float\n",
    "            Average number of electrons to detect per pattern\n",
    "        dqe : float\n",
    "            Detective quantum efficiency (fraction of electrons detected)\n",
    "            1.0 = perfect detector, 0.7 = typical\n",
    "        spread_sigma : float\n",
    "            Gaussian spread of electron signal (pixels)\n",
    "            0 = point detector, >0 = some blur\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Electron counting data\n",
    "        \"\"\"\n",
    "        # Normalize to probability distribution\n",
    "        prob_map = data.astype(float)\n",
    "        prob_map = prob_map / (np.sum(prob_map) + 1e-10)\n",
    "        \n",
    "        # Sample number of electrons (Poisson distributed)\n",
    "        n_electrons = np.random.poisson(electrons_per_pattern)\n",
    "        \n",
    "        # Apply DQE (some electrons not detected)\n",
    "        n_detected = np.random.binomial(n_electrons, dqe)\n",
    "        \n",
    "        # Initialize output\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_detected > 0:\n",
    "            # Flatten probability map for sampling\n",
    "            prob_flat = prob_map.flatten()\n",
    "            \n",
    "            # Sample electron positions\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_detected,\n",
    "                p=prob_flat,\n",
    "                replace=True\n",
    "            )\n",
    "            \n",
    "            # Convert to 2D indices\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            \n",
    "            if spread_sigma > 0:\n",
    "                # Add some spread to electron positions (point spread function)\n",
    "                for y, x in zip(*positions):\n",
    "                    # Add Gaussian spread\n",
    "                    y_spread = y + np.random.normal(0, spread_sigma)\n",
    "                    x_spread = x + np.random.normal(0, spread_sigma)\n",
    "                    \n",
    "                    # Clip to valid range\n",
    "                    y_int = int(np.clip(y_spread, 0, data.shape[0] - 1))\n",
    "                    x_int = int(np.clip(x_spread, 0, data.shape[1] - 1))\n",
    "                    \n",
    "                    output[y_int, x_int] += 1\n",
    "            else:\n",
    "                # Point detector - just count electrons at each position\n",
    "                for y, x in zip(*positions):\n",
    "                    output[y, x] += 1\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "class BimodalSparseNoise(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Bimodal sparse noise: large spike at zero + Gaussian distribution for signal\n",
    "    \n",
    "    Creates histogram with:\n",
    "    - Large bin at 0 (background, 95-99% of pixels)\n",
    "    - Gaussian distribution centered at signal_mean for non-zero pixels\n",
    "    - Clear separation between background and signal\n",
    "    \n",
    "    This is ideal for training denoisers on sparse data with distinct\n",
    "    background and signal populations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        sparsity_target: float = 0.98,\n",
    "        signal_mean: float = 30.0,\n",
    "        signal_sigma: float = 10.0,\n",
    "        min_signal: float = 5.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply bimodal sparse noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data (used as probability map for signal positions)\n",
    "        sparsity_target : float\n",
    "            Target fraction of zero pixels (0.98 = 98% zeros)\n",
    "        signal_mean : float\n",
    "            Mean value for non-zero signal pixels\n",
    "        signal_sigma : float\n",
    "            Standard deviation for signal distribution\n",
    "        min_signal : float\n",
    "            Minimum value for signal pixels (clips low values)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Bimodal sparse data with clear zero peak and signal distribution\n",
    "        \"\"\"\n",
    "        # Normalize to probability distribution\n",
    "        prob_map = data.astype(float)\n",
    "        total_intensity = np.sum(prob_map)\n",
    "        \n",
    "        if total_intensity > 0:\n",
    "            prob_map = prob_map / total_intensity\n",
    "        else:\n",
    "            prob_map = np.ones_like(prob_map) / prob_map.size\n",
    "        \n",
    "        # Calculate number of signal pixels\n",
    "        total_pixels = data.size\n",
    "        n_signal_pixels = int(total_pixels * (1 - sparsity_target))\n",
    "        \n",
    "        # Initialize output with zeros\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_signal_pixels > 0:\n",
    "            # Sample positions for signal pixels\n",
    "            prob_flat = prob_map.flatten()\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_signal_pixels,\n",
    "                p=prob_flat,\n",
    "                replace=True  # Allow repeating pixels\n",
    "            )\n",
    "            \n",
    "            # Generate signal values from Gaussian distribution\n",
    "            signal_values = np.random.normal(signal_mean, signal_sigma, n_signal_pixels)\n",
    "            \n",
    "            # Clip to minimum signal value\n",
    "            signal_values = np.maximum(signal_values, min_signal)\n",
    "            \n",
    "            # Assign to positions\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            output[positions] = signal_values\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "class LowDoseSparseModel(LowDoseDirectDetector):\n",
    "    \"\"\"\n",
    "    Combined low-dose model with extreme sparsity\n",
    "    \n",
    "    Creates data that is:\n",
    "    - >95% zeros\n",
    "    - Sparse electron counts\n",
    "    - Normally distributed signal in non-zero pixels\n",
    "    - Homogeneous zero background\n",
    "    \"\"\"\n",
    "    \n",
    "    def apply(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        sparsity_target: float = 0.98,\n",
    "        mean_electrons: float = 50,\n",
    "        add_readout: bool = False,\n",
    "        readout_sigma: float = 1.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply extreme low-dose sparse noise model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Input data\n",
    "        sparsity_target : float\n",
    "            Target fraction of zero pixels (0.98 = 98% zeros)\n",
    "        mean_electrons : float\n",
    "            Mean number of electrons per pattern\n",
    "        add_readout : bool\n",
    "            Whether to add readout noise (usually False for counting detectors)\n",
    "        readout_sigma : float\n",
    "            Readout noise standard deviation (if added)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Extremely sparse low-dose data\n",
    "        \"\"\"\n",
    "        # Normalize to probability\n",
    "        prob_map = data.astype(float)\n",
    "        total_intensity = np.sum(prob_map)\n",
    "        \n",
    "        if total_intensity > 0:\n",
    "            prob_map = prob_map / total_intensity\n",
    "        else:\n",
    "            # If input is all zeros, use uniform probability\n",
    "            prob_map = np.ones_like(prob_map) / prob_map.size\n",
    "        \n",
    "        # Sample number of electrons\n",
    "        n_electrons = np.random.poisson(mean_electrons)\n",
    "        \n",
    "        # Calculate how many pixels to activate to achieve sparsity\n",
    "        total_pixels = data.size\n",
    "        target_active_pixels = int(total_pixels * (1 - sparsity_target))\n",
    "        \n",
    "        # Make sure we don't activate more pixels than we have electrons\n",
    "        n_activate = min(n_electrons, target_active_pixels)\n",
    "        \n",
    "        # Sample positions\n",
    "        output = np.zeros_like(data, dtype=float)\n",
    "        \n",
    "        if n_activate > 0:\n",
    "            prob_flat = prob_map.flatten()\n",
    "            indices = np.random.choice(\n",
    "                len(prob_flat),\n",
    "                size=n_activate,\n",
    "                p=prob_flat,\n",
    "                replace=True\n",
    "            )\n",
    "            \n",
    "            # Add counts\n",
    "            positions = np.unravel_index(indices, data.shape)\n",
    "            for y, x in zip(*positions):\n",
    "                output[y, x] += 1\n",
    "        \n",
    "        # Optionally add minimal readout noise\n",
    "        if add_readout:\n",
    "            readout = np.random.normal(0, readout_sigma, data.shape)\n",
    "            output = output + readout\n",
    "            output = np.maximum(output, 0)  # Clip negatives\n",
    "        \n",
    "        return output.astype(data.dtype)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Dose Scaling Functions\n",
    "# ============================================================================\n",
    "\n",
    "def reduce_dose(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    dose_fraction: float = 0.01,\n",
    "    method: str = 'sparse_poisson',\n",
    "    signal_mean: float = 30.0,\n",
    "    signal_sigma: float = 10.0\n",
    ") -> py4DSTEM.DataCube:\n",
    "    \"\"\"\n",
    "    Reduce dose of datacube to simulate low-dose conditions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube with normal dose\n",
    "    dose_fraction : float\n",
    "        Fraction of original dose (0.01 = 1%)\n",
    "    method : str\n",
    "        Method to use:\n",
    "        - 'sparse_poisson': Sparse Poisson sampling\n",
    "        - 'electron_counting': Discrete electron counting\n",
    "        - 'extreme_sparse': Extreme sparsity (>95% zeros)\n",
    "        - 'bimodal': Spike at zero + Gaussian signal distribution (RECOMMENDED)\n",
    "    signal_mean : float\n",
    "        Mean value for signal pixels (only for 'bimodal' method)\n",
    "    signal_sigma : float\n",
    "        Std dev for signal pixels (only for 'bimodal' method)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    py4DSTEM.DataCube\n",
    "        Low-dose datacube\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Bimodal distribution (spike at 0 + Gaussian signal)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.02, \n",
    "    ...                         method='bimodal', signal_mean=30)\n",
    "    \n",
    "    >>> # 1% dose with sparse Poisson\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.01)\n",
    "    \n",
    "    >>> # Discrete electron counting (~100 electrons/pattern)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.01, \n",
    "    ...                         method='electron_counting')\n",
    "    \n",
    "    >>> # Extremely sparse (98% zeros)\n",
    "    >>> low_dose = reduce_dose(datacube, dose_fraction=0.005,\n",
    "    ...                         method='extreme_sparse')\n",
    "    \"\"\"\n",
    "    data = datacube.data\n",
    "    scan_i, scan_j, det_i, det_j = data.shape\n",
    "    \n",
    "    print(f\"Reducing dose to {dose_fraction*100:.2f}% using {method}\")\n",
    "    \n",
    "    # Select model\n",
    "    if method == 'bimodal':\n",
    "        # Bimodal: spike at zero + Gaussian signal\n",
    "        sparsity = 1 - dose_fraction  # dose_fraction = fraction of non-zero pixels\n",
    "        model = BimodalSparseNoise()\n",
    "        params = {\n",
    "            'sparsity_target': sparsity,\n",
    "            'signal_mean': signal_mean,\n",
    "            'signal_sigma': signal_sigma,\n",
    "            'min_signal': 5.0\n",
    "        }\n",
    "    \n",
    "    elif method == 'sparse_poisson':\n",
    "        model = SparsePoissonNoise()\n",
    "        params = {'dose_fraction': dose_fraction, 'ensure_sparse': True}\n",
    "    \n",
    "    elif method == 'electron_counting':\n",
    "        # Calculate electrons per pattern from dose fraction\n",
    "        avg_intensity = np.mean(data)\n",
    "        electrons = avg_intensity * dose_fraction * det_i * det_j\n",
    "        model = ElectronCountingNoise()\n",
    "        params = {'electrons_per_pattern': electrons, 'dqe': 0.95}\n",
    "    \n",
    "    elif method == 'extreme_sparse':\n",
    "        avg_intensity = np.mean(data)\n",
    "        electrons = avg_intensity * dose_fraction * det_i * det_j * 0.1\n",
    "        model = LowDoseSparseModel()\n",
    "        params = {\n",
    "            'sparsity_target': 0.98,\n",
    "            'mean_electrons': electrons,\n",
    "            'add_readout': False\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Apply to all patterns\n",
    "    low_dose_data = np.zeros_like(data)\n",
    "    \n",
    "    total = scan_i * scan_j\n",
    "    for idx, (i, j) in enumerate(np.ndindex(scan_i, scan_j)):\n",
    "        dp = data[i, j, :, :]\n",
    "        low_dose_dp = model.apply(dp, **params)\n",
    "        low_dose_data[i, j, :, :] = low_dose_dp\n",
    "        \n",
    "        if (idx + 1) % max(1, total // 10) == 0:\n",
    "            print(f\"  Progress: {idx+1}/{total}\")\n",
    "    \n",
    "    # Create new datacube\n",
    "    low_dose_cube = py4DSTEM.DataCube(data=low_dose_data)\n",
    "    \n",
    "    if hasattr(datacube, 'calibration'):\n",
    "        low_dose_cube.calibration = datacube.calibration\n",
    "    \n",
    "    # Store metadata\n",
    "    low_dose_cube.metadata['dose_reduction'] = {\n",
    "        'method': method,\n",
    "        'dose_fraction': dose_fraction,\n",
    "        'original_mean': float(np.mean(data)),\n",
    "        'reduced_mean': float(np.mean(low_dose_data)),\n",
    "        'sparsity': float(np.sum(low_dose_data == 0) / low_dose_data.size)\n",
    "    }\n",
    "    \n",
    "    print(f\"Done! Sparsity: {low_dose_cube.metadata['dose_reduction']['sparsity']*100:.1f}% zeros\")\n",
    "    \n",
    "    return low_dose_cube\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Analysis Functions\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_sparsity(datacube: py4DSTEM.DataCube) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Analyze sparsity characteristics of datacube\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Sparsity statistics\n",
    "    \"\"\"\n",
    "    data = datacube.data.astype(float)\n",
    "    \n",
    "    stats = {\n",
    "        'sparsity': np.sum(data == 0) / data.size,\n",
    "        'mean_intensity': np.mean(data),\n",
    "        'median_intensity': np.median(data),\n",
    "        'mean_nonzero': np.mean(data[data > 0]) if np.any(data > 0) else 0,\n",
    "        'fraction_nonzero': np.sum(data > 0) / data.size,\n",
    "        'max_intensity': np.max(data),\n",
    "        'electrons_per_pattern': np.mean(np.sum(data, axis=(2, 3)))\n",
    "    }\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SPARSITY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Sparsity (zeros): {stats['sparsity']*100:.2f}%\")\n",
    "    print(f\"Fraction nonzero: {stats['fraction_nonzero']*100:.2f}%\")\n",
    "    print(f\"Mean intensity (all): {stats['mean_intensity']:.3f}\")\n",
    "    print(f\"Mean intensity (nonzero): {stats['mean_nonzero']:.3f}\")\n",
    "    print(f\"Median intensity: {stats['median_intensity']:.3f}\")\n",
    "    print(f\"Max intensity: {stats['max_intensity']:.1f}\")\n",
    "    print(f\"Avg electrons/pattern: {stats['electrons_per_pattern']:.1f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def visualize_histogram(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    log_scale: bool = True,\n",
    "    bins: int = 100,\n",
    "    title: str = \"Intensity Histogram\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize histogram of datacube intensities\n",
    "    \n",
    "    Useful for checking bimodal distribution:\n",
    "    - Should see large spike at 0\n",
    "    - Separate distribution for signal pixels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Input datacube\n",
    "    log_scale : bool\n",
    "        Use log scale for y-axis (recommended to see both peaks)\n",
    "    bins : int\n",
    "        Number of histogram bins\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    data = datacube.data.flatten().astype(float)\n",
    "    \n",
    "    # Separate zeros and non-zeros for analysis\n",
    "    n_zeros = np.sum(data == 0)\n",
    "    n_nonzeros = np.sum(data > 0)\n",
    "    nonzero_data = data[data > 0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Full histogram including zeros\n",
    "    axes[0].hist(data, bins=bins, color='blue', alpha=0.7, edgecolor='black')\n",
    "    if log_scale:\n",
    "        axes[0].set_yscale('log')\n",
    "    axes[0].set_xlabel('Intensity')\n",
    "    axes[0].set_ylabel('Count (log scale)' if log_scale else 'Count')\n",
    "    axes[0].set_title(f'{title}\\n{n_zeros:,} zeros ({n_zeros/len(data)*100:.1f}%)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram of non-zero values only\n",
    "    if len(nonzero_data) > 0:\n",
    "        axes[1].hist(nonzero_data, bins=bins, color='green', alpha=0.7, edgecolor='black')\n",
    "        axes[1].set_xlabel('Intensity')\n",
    "        axes[1].set_ylabel('Count')\n",
    "        axes[1].set_title(f'Non-Zero Values Only\\n'\n",
    "                         f'n={n_nonzeros:,}, mean={np.mean(nonzero_data):.1f}, '\n",
    "                         f'std={np.std(nonzero_data):.1f}')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        axes[1].axvline(np.mean(nonzero_data), color='red', linestyle='--', \n",
    "                       linewidth=2, label=f'Mean: {np.mean(nonzero_data):.1f}')\n",
    "        axes[1].legend()\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'All zeros', ha='center', va='center',\n",
    "                    transform=axes[1].transAxes, fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HISTOGRAM STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total pixels: {len(data):,}\")\n",
    "    print(f\"Zero pixels: {n_zeros:,} ({n_zeros/len(data)*100:.2f}%)\")\n",
    "    print(f\"Non-zero pixels: {n_nonzeros:,} ({n_nonzeros/len(data)*100:.2f}%)\")\n",
    "    if len(nonzero_data) > 0:\n",
    "        print(f\"\\nNon-zero statistics:\")\n",
    "        print(f\"  Mean: {np.mean(nonzero_data):.2f}\")\n",
    "        print(f\"  Std: {np.std(nonzero_data):.2f}\")\n",
    "        print(f\"  Min: {np.min(nonzero_data):.2f}\")\n",
    "        print(f\"  Max: {np.max(nonzero_data):.2f}\")\n",
    "        print(f\"  Median: {np.median(nonzero_data):.2f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def compare_histograms(\n",
    "    original: py4DSTEM.DataCube,\n",
    "    low_dose: py4DSTEM.DataCube,\n",
    "    log_scale: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare histograms of original and low-dose datacubes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    original : py4DSTEM.DataCube\n",
    "        Original datacube\n",
    "    low_dose : py4DSTEM.DataCube\n",
    "        Low-dose datacube\n",
    "    log_scale : bool\n",
    "        Use log scale for y-axis\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    orig_data = original.data.flatten().astype(float)\n",
    "    low_data = low_dose.data.flatten().astype(float)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Original - full histogram\n",
    "    axes[0, 0].hist(orig_data, bins=100, color='blue', alpha=0.7, edgecolor='black')\n",
    "    if log_scale:\n",
    "        axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].set_xlabel('Intensity')\n",
    "    axes[0, 0].set_ylabel('Count (log)' if log_scale else 'Count')\n",
    "    axes[0, 0].set_title(f'Original\\n{np.sum(orig_data==0)/len(orig_data)*100:.1f}% zeros')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Original - non-zero only\n",
    "    orig_nonzero = orig_data[orig_data > 0]\n",
    "    if len(orig_nonzero) > 0:\n",
    "        axes[0, 1].hist(orig_nonzero, bins=100, color='blue', alpha=0.7, edgecolor='black')\n",
    "        axes[0, 1].set_xlabel('Intensity')\n",
    "        axes[0, 1].set_ylabel('Count')\n",
    "        axes[0, 1].set_title(f'Original (Non-Zero)\\nmean={np.mean(orig_nonzero):.1f}')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Low-dose - full histogram\n",
    "    axes[1, 0].hist(low_data, bins=100, color='green', alpha=0.7, edgecolor='black')\n",
    "    if log_scale:\n",
    "        axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].set_xlabel('Intensity')\n",
    "    axes[1, 0].set_ylabel('Count (log)' if log_scale else 'Count')\n",
    "    axes[1, 0].set_title(f'Low-Dose\\n{np.sum(low_data==0)/len(low_data)*100:.1f}% zeros')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Low-dose - non-zero only\n",
    "    low_nonzero = low_data[low_data > 0]\n",
    "    if len(low_nonzero) > 0:\n",
    "        axes[1, 1].hist(low_nonzero, bins=100, color='green', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_xlabel('Intensity')\n",
    "        axes[1, 1].set_ylabel('Count')\n",
    "        axes[1, 1].set_title(f'Low-Dose (Non-Zero)\\nmean={np.mean(low_nonzero):.1f}, '\n",
    "                            f'std={np.std(low_nonzero):.1f}')\n",
    "        axes[1, 1].axvline(np.mean(low_nonzero), color='red', linestyle='--',\n",
    "                          linewidth=2, label=f'Mean')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize_dose_comparison(\n",
    "    original: py4DSTEM.DataCube,\n",
    "    low_dose: py4DSTEM.DataCube,\n",
    "    scan_pos: Tuple[int, int] = None,\n",
    "    log_scale: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize original vs low-dose patterns\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    original : py4DSTEM.DataCube\n",
    "        Original datacube\n",
    "    low_dose : py4DSTEM.DataCube\n",
    "        Low-dose datacube\n",
    "    scan_pos : tuple, optional\n",
    "        (i, j) position to visualize\n",
    "    log_scale : bool\n",
    "        Use log scale for display\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    scan_i, scan_j = original.data.shape[:2]\n",
    "    \n",
    "    if scan_pos is None:\n",
    "        scan_pos = (scan_i // 2, scan_j // 2)\n",
    "    \n",
    "    i, j = scan_pos\n",
    "    \n",
    "    orig_dp = original.data[i, j, :, :].astype(float)\n",
    "    low_dp = low_dose.data[i, j, :, :].astype(float)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original\n",
    "    if log_scale:\n",
    "        im0 = axes[0].imshow(np.log10(orig_dp + 1), cmap='gray')\n",
    "        axes[0].set_title(f'Original (log scale)\\nScan ({i}, {j})')\n",
    "    else:\n",
    "        im0 = axes[0].imshow(orig_dp, cmap='gray', vmax=np.percentile(orig_dp, 99))\n",
    "        axes[0].set_title(f'Original\\nScan ({i}, {j})')\n",
    "    plt.colorbar(im0, ax=axes[0])\n",
    "    \n",
    "    # Low dose\n",
    "    if log_scale:\n",
    "        im1 = axes[1].imshow(np.log10(low_dp + 1), cmap='gray')\n",
    "        axes[1].set_title('Low Dose (log scale)')\n",
    "    else:\n",
    "        im1 = axes[1].imshow(low_dp, cmap='gray', vmax=np.percentile(low_dp, 99))\n",
    "        axes[1].set_title('Low Dose')\n",
    "    plt.colorbar(im1, ax=axes[1])\n",
    "    \n",
    "    # Difference\n",
    "    diff = orig_dp - low_dp\n",
    "    im2 = axes[2].imshow(diff, cmap='RdBu_r', \n",
    "                         vmin=-np.percentile(np.abs(diff), 99),\n",
    "                         vmax=np.percentile(np.abs(diff), 99))\n",
    "    axes[2].set_title('Difference (Original - Low Dose)')\n",
    "    plt.colorbar(im2, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nPattern statistics at position ({i}, {j}):\")\n",
    "    print(f\"Original: sum={np.sum(orig_dp):.0f}, nonzero={np.sum(orig_dp>0)} pixels\")\n",
    "    print(f\"Low dose: sum={np.sum(low_dp):.0f}, nonzero={np.sum(low_dp>0)} pixels\")\n",
    "    print(f\"Sparsity: {np.sum(low_dp==0)/low_dp.size*100:.1f}% zeros\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Quick workflow function\n",
    "# ============================================================================\n",
    "\n",
    "def create_training_pair(\n",
    "    datacube: py4DSTEM.DataCube,\n",
    "    dose_fraction: float = 0.02,\n",
    "    method: str = 'bimodal',\n",
    "    signal_mean: float = 30.0,\n",
    "    signal_sigma: float = 10.0,\n",
    "    seed: Optional[int] = None\n",
    ") -> Tuple[py4DSTEM.DataCube, py4DSTEM.DataCube]:\n",
    "    \"\"\"\n",
    "    Create training pair for denoising: (clean, noisy)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datacube : py4DSTEM.DataCube\n",
    "        Clean datacube (will be used as target)\n",
    "    dose_fraction : float\n",
    "        For 'bimodal': fraction of non-zero pixels (0.02 = 2% signal, 98% zeros)\n",
    "        For other methods: dose fraction as before\n",
    "    method : str\n",
    "        Noise method to use (default: 'bimodal')\n",
    "    signal_mean : float\n",
    "        Mean value for signal pixels (bimodal method only)\n",
    "    signal_sigma : float\n",
    "        Std dev for signal pixels (bimodal method only)\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clean : py4DSTEM.DataCube\n",
    "        Clean target datacube\n",
    "    noisy : py4DSTEM.DataCube\n",
    "        Low-dose noisy datacube\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Bimodal (recommended): 98% zeros + Gaussian signal at mean=30\n",
    "    >>> clean, noisy = create_training_pair(datacube, dose_fraction=0.02,\n",
    "    ...                                      method='bimodal', signal_mean=30)\n",
    "    \n",
    "    >>> # Extreme sparse (old method)\n",
    "    >>> clean, noisy = create_training_pair(datacube, dose_fraction=0.01,\n",
    "    ...                                      method='extreme_sparse')\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    print(\"Creating training pair for denoising...\")\n",
    "    print(f\"Target: Clean datacube (original)\")\n",
    "    \n",
    "    if method == 'bimodal':\n",
    "        print(f\"Input: Bimodal sparse datacube ({(1-dose_fraction)*100:.1f}% zeros, \"\n",
    "              f\"signal mean={signal_mean})\")\n",
    "    else:\n",
    "        print(f\"Input: Low-dose datacube ({dose_fraction*100:.2f}% dose)\")\n",
    "    \n",
    "    noisy = reduce_dose(\n",
    "        datacube,\n",
    "        dose_fraction=dose_fraction,\n",
    "        method=method,\n",
    "        signal_mean=signal_mean,\n",
    "        signal_sigma=signal_sigma\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAnalyzing clean datacube:\")\n",
    "    clean_stats = analyze_sparsity(datacube)\n",
    "    \n",
    "    print(\"\\nAnalyzing noisy datacube:\")\n",
    "    noisy_stats = analyze_sparsity(noisy)\n",
    "    \n",
    "    print(f\"\\nDose reduction: {clean_stats['mean_intensity']/noisy_stats['mean_intensity']:.1f}x\")\n",
    "    \n",
    "    return datacube, noisy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
